{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> \n",
    "The Data Preprocessing class\n",
    "</h1> \n",
    "\n",
    "Please cite the following paper when using the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import Names\n",
    "import Data\n",
    "\n",
    "class DataPreprocessing():\n",
    "    \"\"\"The Data Processing class\"\"\"\n",
    "\n",
    "    def __init__(self, data_dir):\n",
    "        \"\"\"\n",
    "        Get all files in data_dir\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        param data_dir : the pathname of the data directory\n",
    "        \"\"\"\n",
    "\n",
    "        self.files = glob.glob(data_dir + '**/*.txt', recursive=True) + glob.glob(data_dir + '**/*.csv', recursive=True)\n",
    "\n",
    "    def match_data_names(self):\n",
    "        \"\"\"\n",
    "        Match data file with names file\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        Matched [data_file, names_file] lists\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialization\n",
    "        data_names = []\n",
    "\n",
    "        for names_file in self.files:\n",
    "            # If names file\n",
    "            if names_file.endswith('names.txt'):\n",
    "                names_file_name = os.path.basename(names_file)\n",
    "                names_file_name = names_file_name.replace('names.txt', '')\n",
    "                data_files = []\n",
    "                for data_file in self.files:\n",
    "                    # If data file\n",
    "                    if data_file.endswith('data.txt') or data_file.endswith('data.csv'):\n",
    "                        data_file_name = os.path.basename(data_file)\n",
    "                        data_file_name = data_file_name.replace('.train', '')\n",
    "                        data_file_name = data_file_name.replace('.test', '')\n",
    "                        data_file_name = data_file_name.replace('data.txt', '')\n",
    "                        data_file_name = data_file_name.replace('data.csv', '')\n",
    "                        # If data and names file match\n",
    "                        if data_file_name == names_file_name:\n",
    "                            data_files.append(data_file)\n",
    "\n",
    "                # Update data_names\n",
    "                data_names.append([data_files, names_file])\n",
    "\n",
    "        return data_names\n",
    "\n",
    "    def get_setting_names_data(self, data_files, names_file, result_dir, Setting):\n",
    "        \"\"\"\n",
    "        Data preprocessing\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_files : the pathname of the data files\n",
    "        names_file : the pathname of the names file\n",
    "        result_dir : the pathname of the result directory\n",
    "        Setting : the Setting object\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        The Setting, Names, and Data object\n",
    "        \"\"\"\n",
    "\n",
    "        data_file = data_files[0].replace('.train', '')\n",
    "        data_file = data_file.replace('.test', '')\n",
    "\n",
    "        # Get the Setting object\n",
    "        # If data_file and names_file are in the same directory\n",
    "        if os.path.dirname(data_file) == os.path.dirname(names_file):\n",
    "            result_dir += os.path.basename(os.path.dirname(names_file)) + '/'\n",
    "        else:\n",
    "            result_dir += os.path.basename(os.path.dirname(data_file)) + '/' + os.path.basename(os.path.dirname(names_file)) + '/'\n",
    "        setting = Setting.Setting(names_file, result_dir)\n",
    "\n",
    "        # Get the Names object\n",
    "        names = self.get_names(names_file)\n",
    "\n",
    "        # Get the Data object\n",
    "        data = self.get_data(data_files, setting, names)\n",
    "\n",
    "        if setting.parameter_file_dir is not None:\n",
    "            # Write the parameter file\n",
    "            self.write_parameter_file(data_files, names_file, setting, names)\n",
    "\n",
    "        return [setting, names, data]\n",
    "\n",
    "    def get_names(self, names_file):\n",
    "        \"\"\"\n",
    "        Get the Names object\n",
    "        \n",
    "        Parameters\n",
    "        ----------        \n",
    "        names_file : the pathname of the names file\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        The Names object\n",
    "        \"\"\"\n",
    "\n",
    "        with open(names_file, 'r') as f:\n",
    "            # Read the names file\n",
    "            spamreader = list(csv.reader(f, delimiter='='))\n",
    "\n",
    "        # Declare the Names object\n",
    "        names = Names.Names()\n",
    "\n",
    "        # For each parameter\n",
    "        for para_name in names.para_names:\n",
    "            # For each row in the names file\n",
    "            for i in range(len(spamreader)):\n",
    "                # If spamreader[i] is not empty\n",
    "                if spamreader[i] is not None and len(spamreader[i]) > 0:\n",
    "                    # Get the string on the left-hand side of '='\n",
    "                    str_left = spamreader[i][0]\n",
    "\n",
    "                    # Ignore comments\n",
    "                    if str_left.startswith('#'):\n",
    "                        continue\n",
    "\n",
    "                    if para_name in str_left:\n",
    "                        # If there are values for the parameter\n",
    "                        if len(spamreader[i]) > 1:\n",
    "                            # Get the string on the right-hand side of '='\n",
    "                            str_right = spamreader[i][1]\n",
    "\n",
    "                            # Split the string into strings\n",
    "                            strs = str_right.split(\",\")\n",
    "\n",
    "                            # Get the (non-empty) values\n",
    "                            vals = [str.strip() for str in strs if len(str.strip()) > 0]\n",
    "\n",
    "                            # If vals is not empty\n",
    "                            if len(vals) > 0:\n",
    "                                vals = [float(val) if val.isdigit() is True else val for val in vals]\n",
    "                                self.get_para_vals(names, para_name, vals)\n",
    "\n",
    "        # Get the features\n",
    "        names.features = [feature for feature in names.columns if (feature != names.target\n",
    "                                                                and feature not in names.exclude_features)]\n",
    "\n",
    "        return names\n",
    "\n",
    "    def get_para_vals(self, names, para_name, vals):\n",
    "        \"\"\"\n",
    "        Get parameter values\n",
    "        \n",
    "        Parameters\n",
    "        ----------        \n",
    "        names : the Names object\n",
    "        para_name : the parameter name\n",
    "        vals : the values\n",
    "        \"\"\"\n",
    "\n",
    "        if para_name == 'header':\n",
    "            names.header = int(vals[0])\n",
    "        elif para_name == 'delim_whitespace':\n",
    "            names.delim_whitespace = str(vals[0])\n",
    "        elif para_name == 'sep':\n",
    "            names.sep = str(vals[0])\n",
    "        elif para_name == 'place_holder_for_missing_vals':\n",
    "            names.place_holder_for_missing_vals = str(vals[0])\n",
    "        elif para_name == 'columns':\n",
    "            names.columns = [str(val) for val in vals]\n",
    "        elif para_name == 'target':\n",
    "            names.target = str(vals[0])\n",
    "        elif para_name == 'exclude_features':\n",
    "            names.exclude_features = [str(val) for val in vals]\n",
    "        elif para_name == 'categorical_features':\n",
    "            names.categorical_features = [str(val) for val in vals]\n",
    "\n",
    "    def get_data(self, data_files, setting, names):\n",
    "        \"\"\"\n",
    "        Get the Data object\n",
    "        \n",
    "        Parameters\n",
    "        ----------        \n",
    "        data_files : the pathname of the data files\n",
    "        setting : the Setting object\n",
    "        names : the Names object\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        The Data object\n",
    "        \"\"\"\n",
    "\n",
    "        # If one data file\n",
    "        if len(data_files) == 1:\n",
    "            data_file = data_files[0]\n",
    "\n",
    "            # Get X and y\n",
    "            X, y = self.get_X_y(data_file, names)\n",
    "\n",
    "            # Encode X and y\n",
    "            X, y = self.encode_X_y(X, y, setting, names)\n",
    "\n",
    "            # Randomly choose setting.test_size% of the data for testing\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                                y,\n",
    "                                                                test_size=setting.test_size,\n",
    "                                                                random_state=setting.random_state,\n",
    "                                                                stratify=y)\n",
    "        elif len(data_files) == 2:\n",
    "            training_data_file = data_files[0] if 'train' in data_files[0] else data_files[1]\n",
    "            testing_data_file = data_files[0] if 'test' in data_files[0] else data_files[1]\n",
    "\n",
    "            # Get X_train and y_train\n",
    "            X_train, y_train = self.get_X_y(training_data_file, names)\n",
    "\n",
    "            # Get X_test and y_test\n",
    "            X_test, y_test = self.get_X_y(testing_data_file, names)\n",
    "\n",
    "            # Combine training and testing data\n",
    "            X = pd.concat([X_train, X_test])\n",
    "            y = pd.concat([y_train, y_test])\n",
    "\n",
    "            # Encode X and y\n",
    "            X, y = self.encode_X_y(X, y, setting, names)\n",
    "\n",
    "            X_train = X.iloc[:X_train.shape[0], :]\n",
    "            X_test = X.iloc[X_train.shape[0]:, :]\n",
    "\n",
    "            y_train = y[:y_train.shape[0]]\n",
    "            y_test = y[y_train.shape[0]:]\n",
    "        else:\n",
    "            print(\"Wrong number of data files!\")\n",
    "            exit(1)\n",
    "\n",
    "        # Standardize the features\n",
    "        X_train = setting.scaler.fit_transform(X_train.astype(float))\n",
    "        X_test = setting.scaler.transform(X_test.astype(float))\n",
    "\n",
    "        # Declare the Data object\n",
    "        data = Data.Data(X, X_train, X_test, y, y_train, y_test)\n",
    "\n",
    "        # Update names.features and names.features_I\n",
    "        names.features = list(X.columns)\n",
    "        names.features_I = list(X.columns)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def get_X_y(self, data_file, names):\n",
    "        \"\"\"\n",
    "        Get X and y\n",
    "        \n",
    "        Parameters\n",
    "        ----------        \n",
    "        data_file : the pathname of the data file\n",
    "        names : the Names object\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        The feature and target vector\n",
    "        \"\"\"\n",
    "\n",
    "        # Load data\n",
    "        if names.delim_whitespace is True:\n",
    "            df = pd.read_csv(data_file, header=names.header, delim_whitespace=names.delim_whitespace)\n",
    "        else:\n",
    "            df = pd.read_csv(data_file, header=names.header, sep=names.sep)\n",
    "\n",
    "        # Replace '/' with '_'\n",
    "        df = df.replace('/', '_')\n",
    "\n",
    "        # Replace missing_representation with NaN\n",
    "        df = df.replace(names.place_holder_for_missing_vals, np.NaN)\n",
    "        # Remove rows that contain missing values\n",
    "        df = df.dropna(axis=0)\n",
    "\n",
    "        # Get df.columns\n",
    "        df.columns = list(names.columns)\n",
    "\n",
    "        if len(names.exclude_features) > 0:\n",
    "            # Remove features that should be excluded\n",
    "            df = df.drop(names.exclude_features, axis=1)\n",
    "\n",
    "        # Get the feature vector\n",
    "        X = df[names.features]\n",
    "\n",
    "        # Get the target vector\n",
    "        y = df[names.target]\n",
    "\n",
    "        return [X, y]\n",
    "\n",
    "    def encode_X_y(self, X, y, setting, names):\n",
    "        \"\"\"\n",
    "        Encode X and y\n",
    "        \n",
    "        Parameters\n",
    "        ----------        \n",
    "        X : the feature vector\n",
    "        y : the target vector\n",
    "        setting : the Setting object\n",
    "        names : the Names object\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        The encoded feature and target vector\n",
    "        \"\"\"\n",
    "\n",
    "        # One-hot encoding on categorical features\n",
    "        if len(names.categorical_features) > 0:\n",
    "            X = pd.get_dummies(X, columns=names.categorical_features)\n",
    "\n",
    "        # Cast X to float\n",
    "        X = X.astype(float)\n",
    "\n",
    "        # Encode the target\n",
    "        y = setting.encoder.fit_transform(y)\n",
    "\n",
    "        return [X, y]\n",
    "\n",
    "    def write_parameter_file(self, data_files, names_file, setting, names):\n",
    "        \"\"\"\n",
    "        Write the parameter file\n",
    "        \n",
    "        Parameters\n",
    "        ----------        \n",
    "        data_file : the pathname of the data files\n",
    "        names_file : the pathname of the names file\n",
    "        setting : the Setting object\n",
    "        names : the Names object\n",
    "        \"\"\"\n",
    "\n",
    "        # Make directory\n",
    "        directory = os.path.dirname(setting.parameter_file_dir)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        # Get the parameters\n",
    "        parameters = \"\"\"\n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        ### Parameter file for AnotherLogisticAlgorithm (ALA) classifier\n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        ### The pathname of the data file\n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        data_files = \"\"\" + ', '.join(data_files) + \"\"\"\n",
    "        \n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        ### The pathname of the names file\n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        names_file = \"\"\" + names_file + \"\"\"\n",
    "        \n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        ### The header\n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        header = \"\"\" + str(names.header) + \"\"\"\n",
    "        \n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        ### The delimiter\n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        delim_whitespace = \"\"\" + str(names.delim_whitespace) + \"\"\"\n",
    "        \n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        ### The separator\n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        sep = \"\"\" + str(names.sep) + \"\"\"\n",
    "        \n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        ### The place holder for missing values\n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        place_holder_for_missing_vals = \"\"\" + str(names.place_holder_for_missing_vals) + \"\"\"\n",
    "        \n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        ### The (name of the) columns\n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        columns = \"\"\" + ', '.join(names.columns) + \"\"\"\n",
    "        \n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        ### The (name of the) target\n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        target = \"\"\" + names.target + \"\"\"\n",
    "        \n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        ### The (name of the) features\n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        features = \"\"\" + ', '.join(names.features) + \"\"\"\n",
    "        \n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        ### The (name of the) features that should be excluded\n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        exclude_features = \"\"\" + ', '.join(names.exclude_features) + \"\"\"\n",
    "        \n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        ### The (name of the) categorical features\n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        categorical_features = \"\"\" + ', '.join(names.categorical_features) + \"\"\"\n",
    "        \n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        ### The label encoder\n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        encoder = \"\"\" + str(type(setting.encoder)) + \"\"\"\n",
    "        \n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        ### The percentage of the testing set\n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        test_size = \"\"\" + str(setting.test_size) + \"\"\"\n",
    "        \n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        ### The scaler\n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        scaler = \"\"\" + str(type(setting.scaler)) + \"\"\"\n",
    "        \n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        ### The random state\n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        random_state = \"\"\" + str(setting.random_state) + \"\"\"\n",
    "        \n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        ### The minimum number of samples required for calculating importance\n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        min_samples_importance = \"\"\" + str(setting.min_samples_importance) + \"\"\"\n",
    "        \n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        ### The minimum number of samples required for an interaction\n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        min_samples_interaction = \"\"\" + str(setting.min_samples_interaction) + \"\"\"\n",
    "        \n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        ### The average for precision_recall_fscore_support\n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        average = \"\"\" + ', '.join(setting.average) + \"\"\"\n",
    "        \n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        ### The number of jobs to run in parallel, -1 indicates (all CPUs are used)\n",
    "        ###--------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        n_jobs = \"\"\" + str(setting.n_jobs) + \"\"\"\n",
    "        \"\"\"\n",
    "\n",
    "        parameter_file = setting.parameter_file_dir + setting.parameter_file_name + setting.parameter_file_type\n",
    "        # Write the parameter file\n",
    "        with open(parameter_file, 'w') as f:\n",
    "            f.write(parameters + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
