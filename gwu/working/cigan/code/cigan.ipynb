{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cigan.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":true,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"cells":[{"cell_type":"markdown","metadata":{"id":"nt5cAnU6UcRp","toc":true},"source":["<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n","<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Overview</a></span></li><li><span><a href=\"#The-CIGAN-Class\" data-toc-modified-id=\"The-CIGAN-Class-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>The CIGAN Class</a></span></li></ul></div>"]},{"cell_type":"markdown","metadata":{"id":"pKlbheSUaIwR"},"source":["<b>\n","\n","<p>\n","<center>\n","<font size=\"5\">\n","The CIGAN class\n","</font>\n","</center>\n","</p>\n","</b>"]},{"cell_type":"markdown","metadata":{"id":"rT2SKHw2zlEi"},"source":["# Overview"]},{"cell_type":"markdown","metadata":{"id":"asZWLrJKzlEj"},"source":["This notebook includes the code for the CIGAN class, introduced in the following paper submitted to Journal *Journal of Statistical Software*:\n","- \"CIGAN: A Python Package for Handling Class Imbalance using Generative Adversarial Networks\""]},{"cell_type":"markdown","metadata":{"id":"WJ-IbZqAgILJ"},"source":["# The CIGAN Class"]},{"cell_type":"code","metadata":{"id":"NhDW2N1Mi3oh","executionInfo":{"status":"ok","timestamp":1609356352186,"user_tz":300,"elapsed":3255,"user":{"displayName":"Huang Yuxiao","photoUrl":"","userId":"05167076769245149404"}}},"source":["# The magic below allows us to use tensorflow version 2.x\n","%tensorflow_version 2.x \n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","from joblib import Parallel, delayed\n","import copy\n","\n","class CIGAN():\n","    def __init__(self,\n","                 minor_classes='all',\n","                 coding_size='auto',\n","                 batch_size=32,\n","                 max_iter=10,\n","                 generator_hidden_layer_sizes=[100, 200, 300, 400, 500],\n","                 discriminator_hidden_layer_sizes=[500, 400, 300, 200, 100],\n","                 generator_hidden_layer_activation='selu',\n","                 discriminator_hidden_layer_activation='selu',\n","                 generator_optimizer=keras.optimizers.Adam,\n","                 discriminator_optimizer=keras.optimizers.Adam,\n","                 generator_learning_rate=10 ** -4,\n","                 discriminator_learning_rate=10 ** -4,\n","                 random_seed=42,\n","                 n_jobs=1):\n","        \"\"\"\n","        Initialize the GAN class\n","        \n","        Parameters\n","        ----------\n","        X_train : The training feature matrix\n","        y_train : The training target vector\n","        minor_classes : the list of minority classes need to be oversampled, list of integers or 'all' (all the minority classes)\n","        coding_size : the dimension of the latent gaussian noise, an integer or 'auto' (half of the number of features)\n","        batch_size : the batch size for minibatch gradident descent\n","        max_iter: the maximum epoch for minibatch gradident descent\n","        generator_hidden_layer_sizes : the hidden layer sizes of the generator\n","        discriminator_hidden_layer_sizes : the hidden layer sizes of the discriminator\n","        generator_hidden_layer_activation: the hidden layer activation of the generator\n","        discriminator_hidden_layer_activation: the hidden layer activation of the discriminator\n","        generator_optimizer : the optimizer for the generator, Adam by default\n","        discriminator_optimizer : the optimizer for the discriminator, Adam by default\n","        generator_learning_rate : the learning rate for the generator, 10 ** -3 by default\n","        discriminator_learning_rate : the learning rate for the discriminator, 10 ** -3 by default\n","        random_seed : the random seed\n","        n_jobs : the number of CPU cores used when parallelizing over classes\n","        \"\"\"\n","        \n","        # Get the number of rows and columns in X_train\n","        self.m, self.n = X_train.shape\n","        \n","        # Get the classes and their number of samples\n","        self.classes, self.unique_counts = np.unique(y_train, return_counts=True)\n","\n","        # Get the list of minority classes need to be oversampled, list of integers or 'all' (all the minority classes)\n","        self.minor_classes = [self.classes[i] for i in range(len(self.classes)) if self.unique_counts[i] < np.max(self.unique_counts)] if minor_classes == 'all' else minor_classes\n","        \n","        # Get the dimension of the latent gaussian noise, an integer or 'auto' (half of the number of features)\n","        self.coding_size = self.n // 2 if coding_size == 'auto' else coding_size\n","        \n","        # Get the batch size for minibatch gradident descent\n","        self.batch_size = batch_size\n","        \n","        # Get the maximum epoch for minibatch gradident descent\n","        self.max_iter = max_iter\n","\n","        # Get the hidden layer sizes of the generator\n","        self.generator_hidden_layer_sizes = generator_hidden_layer_sizes\n","\n","        # Get the hidden layer sizes of the discriminator\n","        self.discriminator_hidden_layer_sizes = discriminator_hidden_layer_sizes\n","\n","        # Get the hidden layer activation of the generator\n","        self.generator_hidden_layer_activation = generator_hidden_layer_activation\n","\n","        # Get the hidden layer activation of the discriminator\n","        self.discriminator_hidden_layer_activation = discriminator_hidden_layer_activation\n","        \n","        # Get the optimizer for the generator, Adam by default\n","        self.generator_optimizer = generator_optimizer\n","        \n","        # Get the optimizer for the discriminator, Adam by default\n","        self.discriminator_optimizer = discriminator_optimizer\n","        \n","        # Get the learning rate for the generator, 10 ** -3 by default\n","        self.generator_learning_rate = generator_learning_rate\n","        \n","        # Get the learning rate for the discriminator, 10 ** -3 by default\n","        self.discriminator_learning_rate = discriminator_learning_rate\n","        \n","        # Get the random seed\n","        self.random_seed = random_seed\n","\n","        # The number of CPU cores used when parallelizing over classes \n","        self.n_jobs = n_jobs\n","        \n","    def fit_resample(self, X_train, y_train):\n","        \"\"\"\n","        Oversample the minority classses\n","        \n","        Parameters\n","        ----------\n","        X_train : The training feature matrix\n","        y_train : The training target vector\n","        \n","        Returns\n","        ----------\n","        The augmented training feature matrix and target vector\n","        \"\"\"\n","        \n","        # Initialize the augmented training feature matrix\n","        self.X_gan_train = copy.deepcopy(X_train)\n","        \n","        # Initialize the augmented training target vector\n","        self.y_gan_train = copy.deepcopy(y_train)\n","        \n","        # Set backend=\"multiprocessing\" (default) to prevent sharing memory between parent and threads\n","        Parallel(n_jobs=self.n_jobs)(delayed(self.oversample)(X_train, y_train, minor_class)\n","        for minor_class in self.minor_classes)   \n","        \n","        return [self.X_gan_train, self.y_gan_train]\n","    \n","    def oversample(self, X_train, y_train, minor_class):\n","        \"\"\"\n","        Oversample a minority classs\n","        \n","        Parameters\n","        ----------\n","        X_train : The training feature matrix\n","        y_train : The training target vector\n","        minor_class : A minority class\n","        \"\"\"\n","        \n","        # Build GAN\n","        self.build_gan()\n","        \n","        # Compile GAN\n","        self.compile_gan()\n","        \n","        # Train GAN\n","        self.train_gan(X_train, y_train, minor_class)\n","        \n","        # Augment the training data by adding samples generated for the minority class\n","        self.augment(minor_class)\n","        \n","    def build_gan(self):\n","        \"\"\"\n","        Build GAN\n","        \"\"\"\n","        \n","        # Build the generator\n","        self.build_generator()\n","        \n","        # Build the discriminator\n","        self.build_discriminator()\n","        \n","        # Build GAN\n","        self.gan = keras.models.Sequential([self.generator, self.discriminator])\n","        \n","    def build_generator(self):\n","        \"\"\"\n","        Build the generator\n","        \"\"\"\n","        \n","        # Initialize the generator\n","        self.generator = keras.models.Sequential()\n","        \n","        # For each hidden layer\n","        for i in range(len(self.generator_hidden_layer_sizes)):\n","            # Get the layer_size\n","            layer_size = self.generator_hidden_layer_sizes[i]\n","            \n","            # If it is the first hidden layer\n","            if i == 0:\n","                # Get the layer\n","                layer = keras.layers.Dense(layer_size,\n","                                           activation=self.generator_hidden_layer_activation,\n","                                           input_shape=[self.coding_size])\n","            # If it is not the first hidden layer            \n","            else:\n","                # Get the layer\n","                layer = keras.layers.Dense(layer_size,\n","                                           activation=self.generator_hidden_layer_activation)                \n","            # Add the layer to the generator\n","            self.generator.add(layer)\n","        \n","        # Add the output layer to the generator\n","        self.generator.add(keras.layers.Dense(self.n, activation='sigmoid'))\n","        \n","    def build_discriminator(self):\n","        \"\"\"\n","        Build the discriminator\n","        \"\"\"\n","        \n","        # Initialize the discriminator\n","        self.discriminator = keras.models.Sequential()\n","\n","        # Add the first hidden layer to the discriminator\n","        self.discriminator.add(keras.layers.Dense(self.n))\n","        \n","        # For each hidden layer\n","        for i in range(len(self.discriminator_hidden_layer_sizes)):\n","            # Get the layer_size\n","            layer_size = self.discriminator_hidden_layer_sizes[i]\n","            \n","            # Get the layer\n","            layer = keras.layers.Dense(layer_size,\n","                                       activation=self.discriminator_hidden_layer_activation)                \n","            \n","            # Add the layer to the discriminator\n","            self.discriminator.add(layer)    \n","            \n","        # Add the output layer to the discriminator\n","        self.discriminator.add(keras.layers.Dense(1, activation='sigmoid'))\n","        \n","    def compile_gan(self):\n","        \"\"\"\n","        Compile GAN\n","        \"\"\"\n","        \n","        # Compile the discriminator\n","        self.discriminator.compile(loss='binary_crossentropy',\n","                                   optimizer=self.discriminator_optimizer(learning_rate=self.discriminator_learning_rate))\n","        # Freeze the discriminator\n","        self.discriminator.trainable = False\n","\n","        # Compile the generator\n","        self.gan.compile(loss='binary_crossentropy',\n","                         optimizer=self.generator_optimizer(learning_rate=self.generator_learning_rate))\n","        \n","    def train_gan(self, X_train, y_train, minor_class):\n","        \"\"\"\n","        Train GAN\n","        \n","        Parameters\n","        ----------\n","        X_train : The training feature matrix\n","        y_train : The training target vector\n","        minor_class : A minority class\n","        \"\"\"\n","        \n","        # Get the training feature matrix of the minority class\n","        X_minor_train = X_train[np.where(y_train == minor_class)]\n","\n","        # Get the training target vector of the minority class\n","        y_minor_train = y_train[np.where(y_train == minor_class)]\n","\n","        # Get the indices of the training data of the minority class\n","        idxs_minor_train = np.array(range(X_minor_train.shape[0]))\n","\n","        # Get the number of minibatches\n","        n_batch = len(idxs_minor_train) // self.batch_size\n","\n","        # For each epoch\n","        for _ in range(self.max_iter):\n","            # Shuffle the data\n","            np.random.RandomState(seed=self.random_seed).shuffle(idxs_minor_train)\n","\n","            # For each minibatch\n","            for i in range(n_batch):\n","                # Get the first and last index (exclusive) of the minibatch\n","                first_idx = i * self.batch_size\n","                last_idx = min((i + 1) * self.batch_size, len(idxs_minor_train))\n","\n","                # Get the minibatch\n","                mb = idxs_minor_train[first_idx : last_idx]\n","\n","                # Get the real feature matrix\n","                real_features = X_minor_train[mb, :]\n","\n","                # Get the noise\n","                noise = tf.random.normal(shape=[len(mb), self.coding_size], seed=self.random_seed)\n","\n","                # Get the generated feature matrix\n","                gen_features = self.generator(noise)\n","\n","                # Cominbe the generated and real feature matrix\n","                gen_real_features = tf.concat([gen_features, real_features], axis=0)\n","\n","                # Get the target vector\n","                y = tf.constant([[0.]] * len(mb) + [[1.]] * len(mb))\n","\n","                # Unfreeze the discriminator\n","                self.discriminator.trainable = True\n","\n","                # Train the discriminator\n","                self.discriminator.train_on_batch(gen_real_features, y)\n","\n","                # Get the noise\n","                noise = tf.random.normal(shape=[len(mb), self.coding_size], seed=self.random_seed)\n","\n","                # Get the target\n","                y = tf.constant([[1.]] * len(mb))\n","\n","                # Freeze the discriminator\n","                self.discriminator.trainable = False\n","\n","                # Train the generator\n","                self.gan.train_on_batch(noise, y)\n","\n","            # Save GAN\n","            self.gan.save(abspath_curr + '/result/model/' + str(minor_class) + '/model.h5')\n","    \n","    def augment(self, minor_class):\n","        \"\"\"\n","        Augment the training data by adding samples generated for the minority class\n","        \n","        Parameters\n","        ----------\n","        minor_class : A minority class\n","        \"\"\"\n","        \n","        # Get the number of majority class\n","        n_major_class = np.max(self.unique_counts)\n","        \n","        # Get the number of minority class\n","        n_minor_class = self.unique_counts[self.classes[np.where(self.classes == minor_class)][0]]\n","\n","        # Get the difference between the number of majority class and minority class\n","        n_class_diff = n_major_class - n_minor_class\n","\n","        # Initialize the generated data\n","        gen_data = np.zeros((n_class_diff, self.n + 1))\n","\n","        # For each sample\n","        for i in range(n_class_diff):\n","            # Get the noise\n","            noise = tf.random.normal(shape=[1, self.coding_size], seed=self.random_seed)\n","\n","            # Get the generated features\n","            gen_features = self.generator(noise)\n","\n","            # Update the generated data\n","            gen_data[i, :-1], gen_data[i, -1] = gen_features, minor_class\n","            \n","        # Augment the training feature matrix\n","        self.X_gan_train = np.vstack((self.X_gan_train, gen_data[:, :-1]))\n","\n","        # Augment the training target vector\n","        self.y_gan_train = np.vstack((self.y_gan_train.reshape(-1, 1), gen_data[:, -1].reshape(-1, 1))).reshape(-1)      "],"execution_count":1,"outputs":[]}]}