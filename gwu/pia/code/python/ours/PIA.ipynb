{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> \n",
    "Principle Interaction Analysis\n",
    "</h1> \n",
    "\n",
    "Please cite the following paper when using the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import prod\n",
    "from scipy import stats\n",
    "import random\n",
    "\n",
    "class PIA:\n",
    "    \"\"\"\n",
    "    Principle Interaction Analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, min_samples_importance=2, min_samples_interaction=2, p_val=0.01, random_state=0):                     \n",
    "        # The minimum number of samples required for calculating importance\n",
    "        self.min_samples_importance = min_samples_importance\n",
    "        \n",
    "        # The minimum number of samples required for an interaction\n",
    "        self.min_samples_interaction = min_samples_interaction\n",
    "        \n",
    "        # The p-val cutoff\n",
    "        self.p_val = p_val\n",
    "        \n",
    "        # The random_state\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # Set random seed\n",
    "        np.random.RandomState(seed=self.random_state)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the FIDA classifier\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : the feature vector\n",
    "        y : the target vector\n",
    "        \"\"\"\n",
    "\n",
    "        # The distribution of each class\n",
    "        self.dist = {}\n",
    "        \n",
    "        # The disjunction of detected interactions\n",
    "        self.D = {}\n",
    "        \n",
    "        # For each class of the target\n",
    "        for class_ in sorted(np.unique(y)):\n",
    "            # Get the distribution of class_\n",
    "            self.dist[class_] = [1 if class_ == y[i] else 0 for i in range(X.shape[0])]\n",
    "        \n",
    "            self.D[class_] = []\n",
    "            \n",
    "            # The conditions that have been removed\n",
    "            self.removed = {}\n",
    "        \n",
    "            # The conditions that have been deleted\n",
    "            self.deleted = {}\n",
    "        \n",
    "            # The conjunction\n",
    "            C = []\n",
    "            \n",
    "            # Greedy search\n",
    "            self.greedy_search(X, y, class_, C)\n",
    "              \n",
    "    def greedy_search(self, X, y, class_, C):\n",
    "        \"\"\"\n",
    "        Greedy search\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : the feature vector\n",
    "        y : the target vector\n",
    "        class_ : a class of the target\n",
    "        C : a conjunction of conditions\n",
    "        \"\"\"\n",
    "            \n",
    "        # Do, while one of the following three requirements is met\n",
    "        # 1. C is sufficient\n",
    "        # 2. add_best returns [C, True]\n",
    "        # 3. remove_worst returns [C, True]\n",
    "        while True:\n",
    "            # If C is sufficient\n",
    "            if self.sufficient(X, y, class_, C) is True:\n",
    "                # Remove the unnecessary conditions from C\n",
    "                C = self.remove_unnecessary(X, y, class_, C)\n",
    "    \n",
    "                # print('sufficient!', class_, self.decode(C))\n",
    "        \n",
    "                # Get the samples where C is true\n",
    "                C_samples = self.get_samples(X, C)\n",
    "                # Get the distribution of class_ where C is true\n",
    "                dist_C = [1 if class_ == y[i] else 0 for i in C_samples]\n",
    "                # Get the probability, P(class_ | C)\n",
    "                prob = np.mean(dist_C)\n",
    "\n",
    "                # Add [C, prob] to D\n",
    "                self.D[class_].append([C, prob])\n",
    "                \n",
    "                # Clear removed\n",
    "                self.removed = {}\n",
    "                \n",
    "                for c in C:\n",
    "                    # Get a subset of C by excluding c\n",
    "                    C_setminus_c = [x for x in C if x != c]   \n",
    "                    \n",
    "                    # Recursively call greedy_search using the above subset of C\n",
    "                    self.greedy_search(X, y, class_, C_setminus_c)\n",
    "                \n",
    "                # Delete the conditions\n",
    "                for c in C:\n",
    "                    self.deleted[c] = 1\n",
    "                    \n",
    "                # Initialize the conjunction\n",
    "                C = []\n",
    "                    \n",
    "            # If C is not sufficient\n",
    "            else:\n",
    "                C, success = self.add_best(X, y, class_, C)\n",
    "                \n",
    "                if success is False:\n",
    "                    C, success = self.remove_worst(X, y, class_, C)\n",
    "                    \n",
    "                    if success is False:\n",
    "                        C = self.remove_random(X, y, class_, C, 0)\n",
    "                        \n",
    "                        if len(C) == 0:\n",
    "                            break\n",
    "                \n",
    "    def sufficient(self, X, y, class_, C):\n",
    "        \"\"\"\n",
    "        The sufficient condition\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : the feature vector\n",
    "        y : the target vector\n",
    "        class_ : a class of the target\n",
    "        C : a conjunction of conditions\n",
    "        \n",
    "        Returns\n",
    "        ----------    \n",
    "        True : if the sufficient condition is met\n",
    "        False : otherwise\n",
    "        \"\"\"\n",
    "        \n",
    "        # Check if P(class_ | C) >> P(class_)\n",
    "        if self.sig(X, y, class_, C, []) is False:\n",
    "            return False\n",
    "        \n",
    "        # For each condition that is not in C\n",
    "        for x in range(X.shape[1]):\n",
    "            if x in C:\n",
    "                continue\n",
    "            # Check if P(class_ | C and not x) >> P(class_)\n",
    "            if self.sig(X, y, class_, C, [x]) is False:\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "    \n",
    "    def sig(self, X, y, class_, C, xs):\n",
    "        \"\"\"\n",
    "        Check if P(class_ | C and not xs) >> P(class_)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : the feature vector\n",
    "        y : the target vector\n",
    "        class_ : a class of the target\n",
    "        C : a conjunction of conditions\n",
    "        xs : a conjunction of conditions\n",
    "        \n",
    "        Returns\n",
    "        ----------    \n",
    "        True : if P(class_ | C and not xs) >> P(class_)\n",
    "        False : otherwise\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get the distribution of class_\n",
    "        dist = self.dist[class_]\n",
    "        \n",
    "        # If there are no sufficient samples, class_ cannot be used, return False\n",
    "        if len(dist) < self.min_samples_importance:\n",
    "            return False  \n",
    "        \n",
    "        # Get the samples where C is true\n",
    "        C_samples = self.get_samples(X, C)     \n",
    "        # Get the samples where xs is false\n",
    "        not_xs_samples = self.get_not_samples(X, xs)   \n",
    "        # Get the samples where C is true and xs is false\n",
    "        C_and_not_xs_samples = list(set(C_samples) & set(not_xs_samples))\n",
    "        # Get the distribution of class_ where C is true and xs is false\n",
    "        dist_C_and_not_xs = [1 if class_ == y[i] else 0 for i in C_and_not_xs_samples]\n",
    "        \n",
    "        # If there are no sufficient samples, xs cannot be used, return True\n",
    "        if len(dist_C_and_not_xs) < self.min_samples_importance:\n",
    "            return True\n",
    "\n",
    "        # Get the p-value using the t-test\n",
    "        statistics, p_val = stats.ttest_ind(dist_C_and_not_xs, dist, equal_var=False)\n",
    "                \n",
    "        return True if statistics > 0 and p_val < self.p_val else False\n",
    "    \n",
    "    def get_samples(self, X, C):\n",
    "        \"\"\"\n",
    "        Get the samples where every condition in C is true\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : the feature vector\n",
    "        C : a conjunction of conditions\n",
    "        \n",
    "        Returns\n",
    "        ----------    \n",
    "        The samples where every condition in C is true\n",
    "        \"\"\"      \n",
    "        \n",
    "        if len(C) > 0:  \n",
    "            return [i for i in range(X.shape[0]) if prod(X[i, C]) == 1]\n",
    "        else:\n",
    "            return [i for i in range(X.shape[0])]\n",
    "    \n",
    "    def get_not_samples(self, X, C):\n",
    "        \"\"\"\n",
    "        Get the samples where at least one condition in C is not true\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : the feature vector\n",
    "        C : a conjunction of conditions\n",
    "        \n",
    "        Returns\n",
    "        ----------    \n",
    "        The samples where at least one condition in C is not true\n",
    "        \"\"\"\n",
    "        \n",
    "        if len(C) > 0:  \n",
    "            return [i for i in range(X.shape[0]) if prod(X[i, C]) == 0]\n",
    "        else:\n",
    "            return [i for i in range(X.shape[0])]     \n",
    "                \n",
    "    def remove_unnecessary(self, X, y, class_, C):\n",
    "        \"\"\"\n",
    "        Remove the unnecessary conditions from C\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : the feature vector\n",
    "        y : the target vector\n",
    "        class_ : a class of the target\n",
    "        C : a conjunction of conditions\n",
    "        \n",
    "        Returns\n",
    "        ----------    \n",
    "        A subset of C where each condition is necessary        \n",
    "        \"\"\"\n",
    "        \n",
    "        while True:\n",
    "            # Record the size of C\n",
    "            size = len(C)\n",
    "            \n",
    "            # Get the condition-importance pairs\n",
    "            c_importances = self.get_c_importances(X, y, class_, C, C)\n",
    "            \n",
    "            # Sort the condition-importance pairs in ascending order of importance\n",
    "            c_importances_sorted = sorted(c_importances, key=lambda x : x[1], reverse=False)\n",
    "            \n",
    "            for c, importance in c_importances_sorted:\n",
    "                # Remove c from c_importances_sorted\n",
    "                C_setminus_c = [c_importance[0] for c_importance in c_importances_sorted if c_importance[0] != c]\n",
    "                \n",
    "                # If c is not necessary\n",
    "                if self.sufficient(X, y, class_, C_setminus_c) is True:\n",
    "                    # Remove c from C\n",
    "                    C.remove(c)\n",
    "                    break\n",
    "                    \n",
    "            # If all conditions are necessary\n",
    "            if size == len(C):\n",
    "                break\n",
    "                \n",
    "        return C\n",
    "    \n",
    "    def get_c_importances(self, X, y, class_, C, cs):\n",
    "        \"\"\"\n",
    "        Get the condition-importance pairs, where:\n",
    "        the condition, c, in a pair is a condition in cs\n",
    "        the importance is the one of c with respect to C\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : the feature vector\n",
    "        y : the target vector\n",
    "        class_ : a class of the target\n",
    "        C : a conjunction of conditions\n",
    "        cs : a conjunction of conditions\n",
    "        \n",
    "        Returns\n",
    "        ----------    \n",
    "        The condition-importance pairs        \n",
    "        \"\"\"        \n",
    "        \n",
    "        # Get the importance of each condition\n",
    "        importances = [self.get_importance(X, y, class_, C, c) for c in cs]\n",
    "                \n",
    "        # Get the condition-importance pairs\n",
    "        c_importances = [[cs[i], importances[i]] for i in range(len(cs)) if importances[i] is not None]\n",
    "        \n",
    "        return c_importances\n",
    "    \n",
    "    def get_importance(self, X, y, class_, C, c):\n",
    "        \"\"\"\n",
    "        Get the importance of condition c with respect to conjunction C\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : the feature vector\n",
    "        y : the target vector\n",
    "        class_ : a class of the target\n",
    "        C : a conjunction of conditions\n",
    "        c : a condition\n",
    "        \n",
    "        Returns\n",
    "        ----------    \n",
    "        The importance of condition c with respect to conjunction C    \n",
    "        \"\"\" \n",
    "        \n",
    "        # Get C_and_c\n",
    "        C_and_c = list(C)\n",
    "        if c not in C_and_c:\n",
    "            C_and_c.append(c)\n",
    "        # Get the samples where C_and_c is true\n",
    "        C_and_c_samples = self.get_samples(X, C_and_c)\n",
    "        # Get the distribution of class_ where C_and_c is true\n",
    "        dist_C_and_c = [1 if class_ == y[i] else 0 for i in C_and_c_samples]\n",
    "        \n",
    "        # Get C \\setminus c\n",
    "        C_setminus_c = list(C)\n",
    "        if c in C_setminus_c:\n",
    "            C_setminus_c.remove(c)\n",
    "        # Get the samples where C_setminus_c is true\n",
    "        C_setminus_c_samples = self.get_samples(X, C_setminus_c)     \n",
    "        # Get the samples where c is false\n",
    "        not_c_samples = self.get_not_samples(X, [c])   \n",
    "        # Get the samples where C_setminus_c is true and c is false\n",
    "        C_setminus_c_and_not_c_samples = list(set(C_setminus_c_samples) & set(not_c_samples))\n",
    "        # Get the distribution where C_setminus_c is true and c is false\n",
    "        dist_C_setminus_c_and_not_c = [1 if class_ == y[i] else 0 for i in C_setminus_c_and_not_c_samples]\n",
    "                \n",
    "        if len(dist_C_and_c) < self.min_samples_importance or len(dist_C_setminus_c_and_not_c) < self.min_samples_importance:\n",
    "            importance = None\n",
    "        else:\n",
    "            importance = np.mean(dist_C_and_c) - np.mean(dist_C_setminus_c_and_not_c)\n",
    "\n",
    "        return importance\n",
    "    \n",
    "    def add_best(self, X, y, class_, C):\n",
    "        \"\"\"\n",
    "        Across the conditions that meet all of the following four requirements\n",
    "        Add the one, c, with the highest importance\n",
    "        1. c is not in C\n",
    "        2. c has not been removed or deleted\n",
    "        3. C_and_c is not a superset of any detected interaction\n",
    "        4. the importance of c with respect to C is not None\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : the feature vector\n",
    "        y : the target vector\n",
    "        class_ : a class of the target\n",
    "        C : a conjunction of conditions\n",
    "        \n",
    "        Returns\n",
    "        ----------    \n",
    "        [C_and_c, True] : if the above condition, c, exists \n",
    "        [C, False] : otherwise \n",
    "        \"\"\"\n",
    "        \n",
    "        # The list of c meeting requirements 1-3\n",
    "        cs = []\n",
    "        \n",
    "        for c in range(X.shape[1]):\n",
    "            # If requirement 1 is not met\n",
    "            if c in C:\n",
    "                continue\n",
    "\n",
    "            # If requirement 2 is not met\n",
    "            if c in self.removed.keys() or c in self.deleted.keys():\n",
    "                continue\n",
    "                \n",
    "            # Get C_and_c\n",
    "            C_and_c = list(C)\n",
    "            C_and_c.append(c)\n",
    "            \n",
    "            # If requirement 3 is not met\n",
    "            if self.super_set(class_, C_and_c) is True:\n",
    "                continue\n",
    "                \n",
    "            cs.append(c)  \n",
    "                            \n",
    "        # Get the condition-importance pairs\n",
    "        c_importances = self.get_c_importances(X, y, class_, C, cs)        \n",
    "        \n",
    "        if len(c_importances) == 0:\n",
    "            return [C, False]\n",
    "\n",
    "        # Sort the condition-importance pairs in descending order of importance\n",
    "        c_importances_sorted = sorted(c_importances, key=lambda x : x[1], reverse=True)  \n",
    "        # Get the best feature (the one with the highest importance)\n",
    "        best = c_importances_sorted[0][0]\n",
    "        # Add best to C\n",
    "        C.append(best)\n",
    "                \n",
    "        return [C, True]\n",
    "    \n",
    "    def super_set(self, class_, C):\n",
    "        \"\"\"\n",
    "        If C is a superset of interactions of class_\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        class_ : a class of the target\n",
    "        C : a conjunction of conditions\n",
    "        \n",
    "        Returns\n",
    "        ----------    \n",
    "        True : if C is a superset of interactions of class_\n",
    "        False : otherwise \n",
    "        \"\"\"\n",
    "        for I, prob in self.D[class_]:\n",
    "            if set(I) <= set(C):\n",
    "                return True\n",
    "            \n",
    "        return False\n",
    "            \n",
    "    def remove_worst(self, X, y, class_, C):\n",
    "        \"\"\"\n",
    "        Across the conditions that meet all of the following two requirements\n",
    "        Remove the one, c, with the lowest importance\n",
    "        1. c is in C\n",
    "        2. the importance of c with respect to C_set_minus_c is not None\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : the feature vector\n",
    "        y : the target vector\n",
    "        class_ : a class of the target\n",
    "        C : a conjunction of conditions\n",
    "        \n",
    "        Returns\n",
    "        ----------    \n",
    "        [C_set_minus_c, True] : if the above condition, c, exists \n",
    "        [C, False] : otherwise \n",
    "        \"\"\"\n",
    "        \n",
    "        c_importances = self.get_c_importances(X, y, class_, C, C)\n",
    "            \n",
    "        if len(c_importances) == 0:\n",
    "            return [C, False]\n",
    "        \n",
    "        # Sort the condition-importance pairs in ascending order of importance\n",
    "        c_importances_sorted = sorted(c_importances, key=lambda x : x[1], reverse=False) \n",
    "        # Get the worst feature (the one with the lowest importance)\n",
    "        worst = c_importances_sorted[0][0]\n",
    "        # Remove worst from C\n",
    "        C.remove(worst)\n",
    "        # Update self.removed\n",
    "        self.removed[worst] = 1\n",
    "        \n",
    "        return [C, True]\n",
    "    \n",
    "    def remove_random(self, X, y, class_, C, random_state):\n",
    "        \"\"\"\n",
    "        Remove a random condition, c, from C\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : the feature vector\n",
    "        y : the target vector\n",
    "        class_ : a class of the target\n",
    "        C : a conjunction of conditions\n",
    "        random_state : seed from random number generator\n",
    "        \n",
    "        Returns\n",
    "        ----------    \n",
    "        C_set_minus_c\n",
    "        \"\"\"\n",
    "        \n",
    "        if len(C) == 0:\n",
    "            return C\n",
    "        \n",
    "        # Get random_c\n",
    "        random_idx = np.random.randint(low=0, high=len(C))\n",
    "        random_c = C[random_idx]\n",
    "        # Remove random_c from C\n",
    "        C.remove(random_c)\n",
    "        # Update self.removed\n",
    "        self.removed[random_c] = 1\n",
    "        \n",
    "        return C\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transform X by adding interacted features to X \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : the feature vector\n",
    "        \n",
    "        Returns\n",
    "        ----------    \n",
    "        The transformed X\n",
    "        \"\"\"\n",
    "        \n",
    "        X_I = X.copy()\n",
    "        \n",
    "        # For each class of the target\n",
    "        for class_ in self.D.keys():\n",
    "            # For each interaction-probability pair\n",
    "            for I, prob in self.D[class_]:\n",
    "                vals = np.array([1 if prod(X[i, I]) == 1 else 0 for i in range(X.shape[0])]).reshape(-1, 1)\n",
    "                X_I = np.hstack([X_I, vals])\n",
    "                \n",
    "        return X_I\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the class label\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : the feature vector\n",
    "        \n",
    "        Returns\n",
    "        ----------    \n",
    "        The array of predicted class label, y_pred\n",
    "        \"\"\"\n",
    "        \n",
    "        y_pred = []        \n",
    "        \n",
    "        # For each sample\n",
    "        for i in range(X.shape[0]):\n",
    "            # The list of class-probability pairs\n",
    "            class_probs = [[class_, np.mean(self.dist[class_])] for class_ in self.dist]\n",
    "            \n",
    "            # For each class of the target\n",
    "            for class_ in self.D.keys():\n",
    "                # For each interaction-probability pair\n",
    "                for I, prob in self.D[class_]:\n",
    "                    # If the interaction is present\n",
    "                    if prod(X[i, I]) == 1:\n",
    "                        # Add the class-probability pair to the list\n",
    "                        class_probs.append([class_, prob])\n",
    "            \n",
    "            # Sort class_probs in descending order of the probabilities\n",
    "            class_probs = sorted(class_probs, key=lambda x : x[1], reverse=True)\n",
    "            \n",
    "            # The predicted class\n",
    "            class_ = class_probs[0][0]\n",
    "        \n",
    "            # Add the predicted class to the list\n",
    "            y_pred.append(class_)\n",
    "            \n",
    "        return np.array(y_pred)\n",
    "    \n",
    "    def decode(self, C):\n",
    "        return [features[i] for i in C]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>space</th>\n",
       "      <th>target</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>a4</th>\n",
       "      <th>a5</th>\n",
       "      <th>a6</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>data_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>data_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>data_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>data_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>data_7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   space  target  a1  a2  a3  a4  a5  a6      id\n",
       "0    NaN       1   1   1   1   1   1   2  data_2\n",
       "1    NaN       1   1   1   1   1   2   1  data_3\n",
       "2    NaN       1   1   1   1   1   2   2  data_4\n",
       "3    NaN       0   1   1   1   1   3   1  data_5\n",
       "4    NaN       0   1   1   1   1   4   1  data_7"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data', header=None)\n",
    "# df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/balloons/yellow-small+adult-stretch.data',  header=None)\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/monks-problems/monks-3.train', sep=' ', header=None)\n",
    "features = ['a1', 'a2', 'a3', 'a4', 'a5', 'a6']\n",
    "# features = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety']\n",
    "# features = ['color', 'size', 'act', 'age']\n",
    "target = 'target'\n",
    "\n",
    "df.columns = ['space', 'target', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'id']\n",
    "# df.columns = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'target']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a2_1', 'a4_3', 'a5_3', 'a5_4', 'a6_2', 'a3_1', 'a2_2', 'a3_2', 'a2_3', 'a5_2', 'a6_1', 'a1_3', 'a4_2', 'a1_1', 'a5_1', 'a4_1', 'a1_2']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>space</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>a1_1</th>\n",
       "      <th>a1_2</th>\n",
       "      <th>a1_3</th>\n",
       "      <th>a2_1</th>\n",
       "      <th>a2_2</th>\n",
       "      <th>a2_3</th>\n",
       "      <th>a3_1</th>\n",
       "      <th>a3_2</th>\n",
       "      <th>a4_1</th>\n",
       "      <th>a4_2</th>\n",
       "      <th>a4_3</th>\n",
       "      <th>a5_1</th>\n",
       "      <th>a5_2</th>\n",
       "      <th>a5_3</th>\n",
       "      <th>a5_4</th>\n",
       "      <th>a6_1</th>\n",
       "      <th>a6_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>data_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>data_3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>data_4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>data_5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>data_7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   space  target      id  a1_1  a1_2  a1_3  a2_1  a2_2  a2_3  a3_1  a3_2  \\\n",
       "0    NaN       1  data_2     1     0     0     1     0     0     1     0   \n",
       "1    NaN       1  data_3     1     0     0     1     0     0     1     0   \n",
       "2    NaN       1  data_4     1     0     0     1     0     0     1     0   \n",
       "3    NaN       0  data_5     1     0     0     1     0     0     1     0   \n",
       "4    NaN       0  data_7     1     0     0     1     0     0     1     0   \n",
       "\n",
       "   a4_1  a4_2  a4_3  a5_1  a5_2  a5_3  a5_4  a6_1  a6_2  \n",
       "0     1     0     0     1     0     0     0     0     1  \n",
       "1     1     0     0     0     1     0     0     1     0  \n",
       "2     1     0     0     0     1     0     0     0     1  \n",
       "3     1     0     0     0     0     1     0     1     0  \n",
       "4     1     0     0     0     0     0     1     1     0  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=features)\n",
    "\n",
    "features = list(df.columns)\n",
    "\n",
    "features = list(set(features) - set(['space', 'id', 'target']))\n",
    "\n",
    "print(features)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df[features].values, df[target].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 1 0 ..., 0 0 0]\n",
      " [0 1 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]]\n",
      "[[0 0 1 ..., 0 0 0]\n",
      " [0 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 1 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 0 1 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "pia = PIA()\n",
    "pia.fit(X_train, y_train)\n",
    "X_train_I = pia.transform(X_train)\n",
    "X_test_I = pia.transform(X_test)\n",
    "\n",
    "print(X_train_I)\n",
    "print(X_test_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class:  0 ['a2_3']\n",
      "class:  0 ['a5_4']\n",
      "class:  0 ['a1_2', 'a4_2', 'a3_2']\n",
      "class:  0 ['a4_2', 'a5_3', 'a1_2']\n",
      "class:  0 ['a5_3', 'a1_2', 'a4_3']\n",
      "class:  0 ['a1_2', 'a4_3', 'a6_1', 'a3_2']\n",
      "class:  0 ['a4_3', 'a6_1', 'a1_3']\n",
      "class:  0 ['a6_1', 'a1_3', 'a3_2', 'a5_1']\n",
      "class:  0 ['a1_3', 'a3_2', 'a5_1', 'a4_1']\n",
      "class:  0 ['a3_2', 'a5_1', 'a4_1']\n",
      "class:  0 ['a3_2', 'a1_2', 'a6_1']\n",
      "class:  0 ['a1_2', 'a6_1', 'a5_2']\n",
      "class:  0 ['a5_2', 'a3_1', 'a4_2', 'a1_2']\n",
      "class:  0 ['a4_2', 'a1_2', 'a5_2']\n",
      "class:  0 ['a5_2', 'a4_2', 'a1_2']\n",
      "class:  0 ['a1_2', 'a6_1', 'a3_2']\n",
      "class:  1 ['a2_1', 'a5_1']\n",
      "class:  1 ['a5_1', 'a2_2']\n",
      "class:  1 ['a2_2', 'a5_2', 'a1_1']\n",
      "class:  1 ['a5_2', 'a1_1', 'a6_2']\n",
      "class:  1 ['a1_1', 'a6_2', 'a4_3']\n",
      "class:  1 ['a6_2', 'a4_3', 'a5_2']\n",
      "class:  1 ['a4_3', 'a5_2', 'a2_2']\n",
      "class:  1 ['a5_2', 'a2_2', 'a6_2']\n",
      "class:  1 ['a2_2', 'a6_2', 'a1_3']\n",
      "class:  1 ['a6_2', 'a1_3', 'a5_2']\n",
      "class:  1 ['a5_2', 'a2_1']\n",
      "class:  1 ['a2_1', 'a5_3']\n",
      "class:  1 ['a5_3', 'a4_1']\n",
      "class:  1 ['a4_1', 'a2_1', 'a6_2']\n",
      "class:  1 ['a2_1', 'a6_2', 'a1_2']\n",
      "class:  1 ['a6_2', 'a5_2', 'a3_2']\n",
      "class:  1 ['a5_2', 'a3_2', 'a2_2']\n",
      "class:  1 ['a3_2', 'a2_2', 'a4_2']\n",
      "class:  1 ['a2_2', 'a4_2', 'a1_1']\n",
      "class:  1 ['a4_2', 'a1_1', 'a5_2']\n",
      "class:  1 ['a1_1', 'a5_2', 'a3_1']\n",
      "class:  1 ['a5_2', 'a3_1', 'a4_1']\n",
      "class:  1 ['a3_1', 'a4_1', 'a5_1']\n",
      "class:  1 ['a5_1', 'a3_1', 'a6_2']\n",
      "class:  1 ['a6_2', 'a5_2', 'a4_1']\n",
      "class:  1 ['a5_2', 'a4_1', 'a1_3']\n",
      "class:  1 ['a4_1', 'a1_3', 'a2_1']\n",
      "class:  1 ['a1_3', 'a2_1', 'a6_1']\n",
      "class:  1 ['a2_1', 'a6_1', 'a4_3']\n",
      "class:  1 ['a4_3', 'a1_1', 'a3_2']\n",
      "class:  1 ['a1_1', 'a3_2', 'a5_3']\n",
      "class:  1 ['a3_2', 'a5_3', 'a4_3']\n",
      "class:  1 ['a4_3', 'a6_2', 'a5_1']\n",
      "class:  1 ['a6_2', 'a5_1', 'a4_2']\n",
      "class:  1 ['a5_1', 'a4_2', 'a3_2']\n",
      "class:  1 ['a4_2', 'a3_2', 'a5_2']\n",
      "class:  1 ['a3_2', 'a5_2', 'a1_3']\n",
      "class:  1 ['a5_2', 'a1_3', 'a2_2']\n",
      "class:  1 ['a1_3', 'a2_2', 'a5_3']\n",
      "class:  1 ['a2_2', 'a5_3', 'a3_2']\n",
      "class:  1 ['a5_3', 'a1_3', 'a3_1']\n",
      "class:  1 ['a1_3', 'a4_1', 'a2_2', 'a3_2']\n",
      "class:  1 ['a2_2', 'a3_2', 'a1_1', 'a6_1']\n",
      "class:  1 ['a1_1', 'a6_1', 'a5_1', 'a4_2']\n",
      "class:  1 ['a5_1', 'a4_2', 'a1_1']\n",
      "class:  1 ['a4_2', 'a1_1', 'a6_1', 'a3_1']\n",
      "class:  1 ['a1_1', 'a5_1', 'a4_2']\n"
     ]
    }
   ],
   "source": [
    "for class_ in pia.D.keys():\n",
    "    for I, prob in pia.D[class_]:\n",
    "        I_samples = pia.get_samples(X, I)\n",
    "        if len(I_samples) >= pia.min_samples_interaction:\n",
    "            print('class: ', class_, pia.decode(I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.48648648648648651, 0.48648648648648651, 0.48648648648648651, None)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "y_pred = pia.predict(X_test)\n",
    "\n",
    "precision_recall_fscore_support(y_test, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.89189189189189189, 0.89189189189189189, 0.89189189189189189, None)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "precision_recall_fscore_support(y_test, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.89189189189189189, 0.89189189189189189, 0.89189189189189189, None)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_I, y_train)\n",
    "y_pred = clf.predict(X_test_I)\n",
    "\n",
    "precision_recall_fscore_support(y_test, y_pred, average='micro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
